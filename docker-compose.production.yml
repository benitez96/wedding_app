services:
  # App principal
  wedding-app:
    build: .
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://postgres:${POSTGRES_PASSWORD}@db:5432/wedding_app
      - JWT_SECRET=${JWT_SECRET}
      - TZ=America/Argentina/Buenos_Aires
    depends_on:
      db:
        condition: service_healthy
    volumes:
      - /volumes/wedding-app/logs:/app/logs
    restart: unless-stopped
    networks:
      - app_network
      - monitoring_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Base de datos
  db:
    image: postgres:17.6-alpine
    environment:
      - POSTGRES_DB=wedding_app
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - TZ=America/Argentina/Buenos_Aires
    volumes:
      - /volumes/wedding-app/postgres:/var/lib/postgresql/data
    restart: unless-stopped
    networks:
      - app_network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d wedding_app"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Stack de monitoreo - Elasticsearch
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:9.1.2
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - ES_JAVA_OPTS=-Xms1g -Xmx1g
      - cluster.name=wedding-app-cluster
      - node.name=wedding-app-node
      - bootstrap.memory_lock=true
      - TZ=America/Argentina/Buenos_Aires
      - ingest.geoip.downloader.enabled=false
      # GeoIP deshabilitado por restricciones de red interna
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    volumes:
      - /volumes/wedding-app/elasticsearch:/usr/share/elasticsearch/data
    restart: unless-stopped
    networks:
      - monitoring_network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # Stack de monitoreo - Logstash
  logstash:
    image: docker.elastic.co/logstash/logstash:9.1.2
    environment:
      - TZ=America/Argentina/Buenos_Aires
    volumes:
      - ./config/logstash/pipeline:/usr/share/logstash/pipeline
      - /volumes/wedding-app/caddy/logs:/var/log/caddy:ro
      - /var/log/fail2ban.log:/var/log/fail2ban.log:ro
    depends_on:
      elasticsearch:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - monitoring_network

  # Stack de monitoreo - Kibana
  kibana:
    image: docker.elastic.co/kibana/kibana:9.1.2
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - TZ=America/Argentina/Buenos_Aires
    depends_on:
      elasticsearch:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - monitoring_network

  # Stack de monitoreo - Prometheus
  prometheus:
    image: prom/prometheus:v3.5.0
    environment:
      - TZ=America/Argentina/Buenos_Aires
    volumes:
      - ./config/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - /volumes/wedding-app/prometheus:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped
    networks:
      - monitoring_network

  # Stack de monitoreo - Node Exporter
  node-exporter:
    image: prom/node-exporter:v1.9.1
    environment:
      - TZ=America/Argentina/Buenos_Aires
    network_mode: host
    pid: host
    restart: unless-stopped

  # Stack de monitoreo - Grafana
  grafana:
    image: grafana/grafana:12.1.1
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_SERVER_DOMAIN=grafana.${DOMAIN}
      - GF_SERVER_ROOT_URL=https://grafana.${DOMAIN}
      - TZ=America/Argentina/Buenos_Aires
    volumes:
      - /volumes/wedding-app/grafana:/var/lib/grafana
      - ./config/grafana/provisioning:/etc/grafana/provisioning
    restart: unless-stopped
    networks:
      - monitoring_network

  # Reverse Proxy - Caddy (Ãºnico servicio con acceso a internet)
  caddy:
    image: caddy:2-alpine
    ports:
      - "80:80"
      - "443:443"
    env_file:
      - .env
    environment:
      - DOMAIN=${DOMAIN}
      - BASIC_AUTH_HASH=${BASIC_AUTH_HASH}
      - TZ=America/Argentina/Buenos_Aires
    volumes:
      - ./config/caddy/Caddyfile:/etc/caddy/Caddyfile:ro
      - /volumes/wedding-app/caddy/data:/data
      - /volumes/wedding-app/caddy/config:/config
      - /volumes/wedding-app/caddy/logs:/var/log/caddy
    depends_on:
      - wedding-app
      - grafana
      - kibana
      - prometheus
    restart: unless-stopped
    networks:
      - public_network
      - app_network
      - monitoring_network
    command: ["caddy", "run", "--config", "/etc/caddy/Caddyfile", "--adapter", "caddyfile"]

networks:
  public_network:
    driver: bridge
    internal: true  # Solo Caddy puede salir a internet
  monitoring_network:
    driver: bridge
    internal: true  # Red interna, sin acceso a internet
  app_network:
    driver: bridge
    internal: true  # Red interna para app y DB
  # geoip_network:
  #   driver: bridge
  #   # Sin internal: true para permitir acceso a internet solo para GeoIP