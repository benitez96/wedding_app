services:
  # App principal
  wedding-app:
    build: .
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://postgres:${POSTGRES_PASSWORD}@db:5432/wedding_app
      - JWT_SECRET=${JWT_SECRET}
      - TZ=America/Argentina/Buenos_Aires
    depends_on:
      db:
        condition: service_healthy
    volumes:
      - app_logs:/app/logs
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
  # Base de datos
  db:
    image: postgres:17.6-alpine
    environment:
      - POSTGRES_DB=wedding_app
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - TZ=America/Argentina/Buenos_Aires
    volumes:
      - postgres_data:/var/lib/postgresql/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d wedding_app"]
      interval: 10s
      timeout: 5s
      retries: 5

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:9.1.2
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - ES_JAVA_OPTS=-Xms1g -Xmx1g
      - cluster.name=wedding-app-cluster
      - node.name=wedding-app-node
      - bootstrap.memory_lock=true
      - TZ=America/Argentina/Buenos_Aires
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  logstash:
    image: docker.elastic.co/logstash/logstash:9.1.2
    environment:
      - TZ=America/Argentina/Buenos_Aires
    volumes:
      - ./utils/logstash/pipeline:/usr/share/logstash/pipeline
      - caddy_logs:/var/log/caddy:ro
    depends_on:
      elasticsearch:
        condition: service_healthy
    restart: unless-stopped

  kibana:
    image: docker.elastic.co/kibana/kibana:9.1.2
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - TZ=America/Argentina/Buenos_Aires
    depends_on:
      elasticsearch:
        condition: service_healthy
    restart: unless-stopped
  prometheus:
    image: prom/prometheus:v3.5.0
    environment:
      - TZ=America/Argentina/Buenos_Aires
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    extra_hosts:
      - "host.docker.internal:host-gateway"  # para scrapear node-exporter en host
    restart: unless-stopped

  node-exporter:
    image: prom/node-exporter:v1.9.1
    environment:
      - TZ=America/Argentina/Buenos_Aires
    network_mode: host
    pid: host
    restart: unless-stopped

  grafana:
    image: grafana/grafana:12.1.1
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_SERVER_DOMAIN=grafana.${DOMAIN}
      - GF_SERVER_ROOT_URL=https://grafana.${DOMAIN}
      - TZ=America/Argentina/Buenos_Aires
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning
    restart: unless-stopped
  caddy:
    image: caddy:2-alpine
    ports:
      - "80:80"
      - "443:443"
    env_file:
      - .env
    environment:
      - DOMAIN=${DOMAIN}
      - BASIC_AUTH_HASH=${BASIC_AUTH_HASH}
      - TZ=America/Argentina/Buenos_Aires
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile:ro
      - caddy_data:/data
      - caddy_config:/config
      - caddy_logs:/var/log/caddy
    depends_on:
      - wedding-app
      - grafana
      - kibana
      - prometheus
    restart: unless-stopped
    command: ["caddy", "run", "--config", "/etc/caddy/Caddyfile", "--adapter", "caddyfile"]

volumes:
  postgres_data:
  elasticsearch_data:
  prometheus_data:
  grafana_data:
  caddy_data:
  caddy_config:
  caddy_logs:
  app_logs: